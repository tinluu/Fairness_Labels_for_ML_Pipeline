{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessLabel:\n",
    "    \n",
    "    def __init__(self, data, model_flag, sensitive_attrs, protected_values, target):\n",
    "        \n",
    "        self.model_flag = model_flag\n",
    "        self.data = data\n",
    "        self.sensitive = sensitive_attrs \n",
    "        self.target = target\n",
    "\n",
    "        self.static_label = {}\n",
    "        \n",
    "        #self.performance_label = {}\n",
    "        \n",
    "\n",
    "    def extract_static_label2(self):\n",
    "        ''' all we need: 1) sensitive attributes, and 2) target '''\n",
    "        \n",
    "        #Level 1 \n",
    "        for attr in self.sensitive:\n",
    "            _target = {}\n",
    "            populations = dict(self.data[attr].value_counts())\n",
    "            grouped = self.data.groupby(attr)\n",
    "            for key, value in populations.items():\n",
    "                _target[key] = dict(grouped.get_group(key)[self.target].value_counts()/value)\n",
    "            self.static_label[attr] = _target\n",
    "        \n",
    "        #Level 2 \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "   \n",
    "    def extract_static_label(self):\n",
    "        # TODO: add extraction code\n",
    "        \n",
    "        # renew self.staic_label\n",
    "            self.static_label = {}\n",
    "    \n",
    "            # update static label\n",
    "            for pair in self.pair_comb:\n",
    "                # temporary dic to store values\n",
    "                static_pair_val =  {}\n",
    "                label1 = pair[0]\n",
    "                label2 = pair[1]\n",
    "                info = {}\n",
    "                \n",
    "                # calculate static label for each pair \n",
    "                for cat1 in self.sensitive_atts[label1]:\n",
    "                    temp_cat2 = {}\n",
    "                    for cat2 in self.sensitive_atts[label2]:\n",
    "                        cat2_count = len(self.data.loc[(self.data[label1] == cat1) &\n",
    "                                                                (self.data[label2] == cat2)])\n",
    "                        temp_cat2.update({cat2:{'positive': cat2_count / len(self.data),\n",
    "                                                    'negative': 1 - (cat2_count / len(self.data))}})\n",
    "                    # UPDATE info for one category \n",
    "                    static_pair_val.update({cat1:temp_cat2})\n",
    "                # UPDATE one pair of info into static_label                       \n",
    "                self.static_label.update({label1: static_pair_val})    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                        \n",
    "    def compute_evaluation_metric(self,data, data_prediction,y_label,positive_label,label_order):\n",
    "        #TODO: add weight for generalized metric\n",
    "    # validity of the input data, must have two labels\n",
    "\n",
    "        if len(data[y_label].unique()) != 2 or len(data_prediction[y_label].unique()) != 2: # compute manually\n",
    "            \n",
    "            TP = data.query(f\"{y_label}=={positive_label}\").shape[0]\n",
    "            TN = data.shape[0] - TP\n",
    "            FP = len(set(data_prediction.query(f\"{y_label}=={positive_label}\").index).intersection(data.query(f\"{y_label}!={positive_label}\").index))\n",
    "            FN = len(set(data_prediction.query(f\"{y_label}!={positive_label}\").index).intersection(data.query(f\"{y_label}=={positive_label}\").index))\n",
    "        else:    \n",
    "            TN, FP, FN, TP = confusion_matrix(list(data[y_label]), list(data_prediction[y_label]), labels=label_order).ravel()\n",
    "        P = TP + FN\n",
    "        N = TN + FP\n",
    "        ACC = (TP+TN) / (P+N) if (P+N) > 0.0 else np.float64(0.0)\n",
    "          \n",
    "        return  dict(\n",
    "                    PR = P/ (P+N), P = TP + FN, N = TN + FP,\n",
    "                    TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
    "                    PPV=TP / (TP+FP) if (TP+FP) > 0.0 else np.float64(0.0),\n",
    "                    NPV=TN / (TN+FN) if (TN+FN) > 0.0 else np.float64(0.0),\n",
    "                    FDR=FP / (FP+TP) if (FP+TP) > 0.0 else np.float64(0.0),\n",
    "                    FOR=FN / (FN+TN) if (FN+TN) > 0.0 else np.float64(0.0),\n",
    "                    ACC=ACC,\n",
    "                    ERR=1-ACC,\n",
    "                    F1=2*TP / (2*TP+FP+FN) if (2*TP+FP+FN) > 0.0 else np.float64(0.0)\n",
    "                )\n",
    "\n",
    "        \n",
    "                        \n",
    "    def compute_fairness_diff(self,data, data_prediction, y_label, positive_label, label_order, sensi_att, protected_v):\n",
    "        all_eval_metrics = self.compute_evaluation_metric(data, data_prediction, y_label, positive_label, label_order)\n",
    "        pro_eval_metrics = self.compute_evaluation_metric(data[(data[sensi_att[0]]==protected_v[0]) & (data[sensi_att[1]]==protected_v[1]) ], data_prediction[(data_prediction[sensi_att[0]]==protected_v[0]) & (data_prediction[sensi_att[1]]==protected_v[1])], y_label, positive_label, label_order)\n",
    "        unpro_eval_metrics = self.compute_evaluation_metric(data[(data[sensi_att[0]]!=protected_v[0]) & (data[sensi_att[1]]!=protected_v[1]) ], data_prediction[(data_prediction[sensi_att[0]]!=protected_v[0]) & (data_prediction[sensi_att[1]]!=protected_v[1])], y_label, positive_label, label_order)\n",
    "        fair_metrics = {}\n",
    "        for mi in pro_eval_metrics:\n",
    "            fair_metrics[mi+\"_D\"] = pro_eval_metrics[mi] - unpro_eval_metrics[mi]\n",
    "            fair_metrics[mi+\"_R\"] = pro_eval_metrics[mi] / unpro_eval_metrics[mi] if unpro_eval_metrics[mi] > 0.0 else np.float64(0.0)\n",
    "        fair_metrics[\"avgODDS_D\"] = 0.5 * (pro_eval_metrics[\"FPR\"] - unpro_eval_metrics[\"FPR\"])\\\n",
    "                    + (pro_eval_metrics[\"TPR\"] - unpro_eval_metrics[\"TPR\"])\n",
    "        fair_metrics[\"avgAODDS_D\"] = 0.5 * np.abs(pro_eval_metrics[\"FPR\"] - unpro_eval_metrics[\"FPR\"])\\\n",
    "                    + np.abs(pro_eval_metrics[\"TPR\"] - unpro_eval_metrics[\"TPR\"])\n",
    "        # ALIASES\n",
    "        fair_metrics[\"DI\"] = fair_metrics[\"PR_R\"]\n",
    "        fair_metrics[\"SP\"] = fair_metrics[\"PR_D\"]\n",
    "        fair_metrics[\"MD\"] = fair_metrics[\"PR_D\"]\n",
    "        fair_metrics[\"ACC\"] = all_eval_metrics[\"ACC\"]\n",
    "\n",
    "\n",
    "        return fair_metrics   \n",
    "                        \n",
    "    \n",
    "    def extract_performance_label(self, data_prediction,y_label,positive_label):\n",
    "        data = self.data\n",
    "        for pair in self.pair_comb:\n",
    "            sensi_att = pair \n",
    "             # USER SPECIFIED PROTECTED CLASS HAS PRIORITY \n",
    "            if sensi_att[0] in self.protected_values.keys() and sensi_att[1] in self.protected_values.keys():\n",
    "                protected_v = [self.protected_values[sensi_att[0]], self.protected_values[sensi_att[1]]]\n",
    "                \n",
    "            else:\n",
    "                protected_v = [self.sensi_atts_values[sensi_att[0]], self.sensi_atts_values[sensi_att[1]] ]\n",
    "                \n",
    "            # label order is the reverse list in sensitive_atts. eg: {race: [white,asian,black]} here will be [black,...]\n",
    "            label_order = self.sensitive_atts[sensi_att[0]].reverse()\n",
    "            performance_label_pair = self.compute_fairness_diff(data, data_prediction, y_label, positive_label, label_order, sensi_att, protected_v)\n",
    "            \n",
    "            self.performance_label.update({'{}+{}'.format(sensi_att[0],sensi_att[1]): performance_label_pair})\n",
    "                \n",
    "    \n",
    "    def add_sensitive_att(self, new_sensitive_att):\n",
    "        # new_sensitive_att is usually a non-traditional sensitive feature like race or gender but user want to treat it as sensitive\n",
    "        # update all the information in the __init__ accordingly\n",
    "        for label in new_sensitive_att:\n",
    "            categories = self.data[label].unique()\n",
    "                # temporarily store each categories and corresponding values \n",
    "            cat_num = []\n",
    "            for cat in categories:\n",
    "                cat_num += [(cat, len(self.data.loc[self.data[label] == cat ]))]\n",
    "                cat_num = sorted(cat_num, key = lambda x: x[1], reverse = True)\n",
    "                # update self.sensitive_atts for each label \n",
    "                self.sensitive_atts.update({label: [cat_num[i][0] for i in range(len(cat_num))]})\n",
    "                # update self.sensi_atts_values for each label \n",
    "                self.sensi_atts_values.update({label: cat_num[-1][0]})\n",
    "        \n",
    "        # auto renew static_label\n",
    "        self.extract_static_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Static Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"race\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sex\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income-per-year\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_attrs = ['sex', 'race']\n",
    "\n",
    "target = \"income-per-year\"\n",
    "\n",
    "model_flag = False \n",
    "\n",
    "fair = FairnessLabel(data, model_flag, sensitive_attrs, ['White','Female'], target)\n",
    "\n",
    "fair.extract_static_label2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': {'Male': {'<=50K': 0.6942634235888022, '>50K': 0.3057365764111978},\n",
       "  'Female': {'<=50K': 0.8905394113824158, '>50K': 0.10946058861758426}},\n",
       " 'race': {'White': {'<=50K': 0.7441400632729365, '>50K': 0.2558599367270636},\n",
       "  'Black': {'<=50K': 0.8761203585147247, '>50K': 0.12387964148527529},\n",
       "  'Asian-Pac-Islander': {'<=50K': 0.7343599615014437,\n",
       "   '>50K': 0.26564003849855633},\n",
       "  'Amer-Indian-Eskimo': {'<=50K': 0.8842443729903537,\n",
       "   '>50K': 0.1157556270096463},\n",
       "  'Other': {'<=50K': 0.9077490774907749, '>50K': 0.09225092250922509}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair.static_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE2: DO NOT PASS VARIABLES TO VARIABLES (static label)\n",
    "data = pd.read_csv('../data/adult.csv')\n",
    "fair = FairnessLabel(data, False)\n",
    "fair.extract_static_label()\n",
    "fair.static_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE3: Performance label\n",
    "data = pd.read_csv('../data/adult.csv')\n",
    "'''\n",
    "\n",
    "target_var = data['income-per-year'].unique()\n",
    "for i, value in enumerate(target_var):\n",
    "    if i == 0 :\n",
    "        data = data.replace(value, 0)\n",
    "    else:\n",
    "        data = data.replace(value, 1)\n",
    "\n",
    "'''\n",
    "fair = FairnessLabel(data, True, ['race','sex','relationship'], ['Black','Female','Not-in-family'])\n",
    "fair.extract_performance_label(data, 'income-per-year' , '<=50K')\n",
    "fair.performance_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
